{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMVXj4h88PhCBeFweJXu/gD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mnishio240/laserscar/blob/main/Untitled0_ipynb_%E3%81%AE%E3%82%B3%E3%83%94%E3%83%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WuTEHqS1Fei",
        "outputId": "80de9e69-e239-4745-e283-626b56dee9af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-cb83dbb9-3f2d-d5df-cfe5-a5acd4dc83d3)\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function, division\n",
        "# !pip install torch_optimizer\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision.models as models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models\n",
        "import torchvision.transforms.v2 as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "import csv\n",
        "import pandas as pd\n",
        "import glob\n",
        "from PIL import Image\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "#あればGPUを使用\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "!nvidia-smi -L\n",
        "\n",
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3人まとめて学習したコード\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.models import ResNet50_Weights\n",
        "from torch.optim import lr_scheduler\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import glob\n",
        "\n",
        "# ✅ 設定\n",
        "PX = 64\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 300\n",
        "PATIENCE = 30\n",
        "NUM_FOLDS = 5\n",
        "\n",
        "# ✅ ファイルパスの指定\n",
        "csv_paths = [\n",
        "    \"/content/drive/MyDrive/Pixel_Comparison2YearsPatient1_Tracks_1_to_1004.csv\",\n",
        "    \"/content/drive/MyDrive/Pixel_Comparison2Y3MPatient13R_Tracks_1_to_1010.csv\",\n",
        "    \"/content/drive/MyDrive/Pixel_Comparison_Patient21R_0MPhoto_1Y3MPhoto.csv\"\n",
        "]\n",
        "\n",
        "cropped_img_dirs = [\n",
        "    \"/content/drive/MyDrive/Patient_1_Cropped\",\n",
        "    \"/content/drive/MyDrive/Patient13R_Cropped\",\n",
        "    \"/content/drive/MyDrive/Patient21R_Cropped\"\n",
        "]\n",
        "\n",
        "first_characters_list = [\"pt1_2_0M\", \"Pt13R_2_0M\", \"Pt21R_2_0M\"]\n",
        "\n",
        "# ✅ 置換辞書（CSV のファイル名を画像フォルダに合わせるための変換）\n",
        "replace_dict = {\n",
        "    \"pt1_2_0M_Photo\": \"pt1_5_1.5M_AF\",\n",
        "    \"Pt13R_2_0M_Photo\": \"Pt13R_4_1MAF\",\n",
        "    \"Pt21R_2_0M_Photo\": \"Pt21R_3_1M_AF\"\n",
        "}\n",
        "\n",
        "# ✅ データの読み込みとフィルタリング（置換を適用して glob 検索を実行）\n",
        "def load_and_filter_data(csv_paths, cropped_img_dirs, first_characters_list):\n",
        "    all_data = []\n",
        "    for csv_path, img_dir, first_characters in zip(csv_paths, cropped_img_dirs, first_characters_list):\n",
        "        print(f\"Processing: {csv_path}\")\n",
        "        df = pd.read_csv(csv_path)\n",
        "        print(f\"Initial DF size: {df.shape}\")\n",
        "\n",
        "        if df.empty:\n",
        "            print(f\"Warning: {csv_path} is empty!\")\n",
        "            continue\n",
        "\n",
        "        if \"File Prefix1\" not in df.columns:\n",
        "            print(f\"Error: 'File Prefix1' column not found in {csv_path}\")\n",
        "            continue\n",
        "\n",
        "        # 空白や改行を削除\n",
        "        df[\"File Prefix1\"] = df[\"File Prefix1\"].str.strip()\n",
        "\n",
        "        # contains() でフィルタリング（大文字小文字は区別せず）\n",
        "        df = df[df[\"File Prefix1\"].str.contains(first_characters, case=False, na=False)]\n",
        "        print(f\"Filtered DF size: {df.shape}\")\n",
        "\n",
        "        # --- ここで置換を適用（画像フォルダのファイル名に合わせるため） ---\n",
        "        for key, value in replace_dict.items():\n",
        "            df[\"File Prefix1\"] = df[\"File Prefix1\"].str.replace(key, value, regex=False)\n",
        "\n",
        "        # glob.glob() の検索パターンを部分一致に変更\n",
        "        # ※ CSV で指定された（置換済みの）ファイル名が、画像フォルダ内のファイル名の一部として存在する場合にヒットさせる\n",
        "        df[\"Image Path\"] = df[\"File Prefix1\"].apply(lambda x: glob.glob(os.path.join(img_dir, \"*\" + x + \"*\")))\n",
        "        df = df.explode(\"Image Path\")\n",
        "        print(f\"After exploding: {df.shape}\")\n",
        "\n",
        "        df.dropna(subset=[\"Image Path\"], inplace=True)\n",
        "        print(f\"Final DF size after dropping NaN: {df.shape}\")\n",
        "\n",
        "        all_data.append(df)\n",
        "\n",
        "    return pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()\n",
        "\n",
        "filtered_df = load_and_filter_data(csv_paths, cropped_img_dirs, first_characters_list)\n",
        "filtered_df = filtered_df.reset_index(drop=True)\n",
        "\n",
        "# ✅ 出力フォルダの作成\n",
        "output_folder = \"results226total\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# ✅ データセット\n",
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, df, transform):\n",
        "        self.transform = transform\n",
        "        self.item_paths = df[\"Image Path\"].tolist()\n",
        "        self.ratio = df[\"Ratio\"].values\n",
        "        # ※ ここで再度置換を行う必要がある場合は追加してください\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.item_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.item_paths[idx]\n",
        "        try:\n",
        "            pil_image = Image.open(image_path).convert(\"RGB\")\n",
        "            tensor_image = self.transform(pil_image)\n",
        "            target = torch.tensor([self.ratio[idx]], dtype=torch.float32)\n",
        "            return tensor_image, target\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image: {image_path}, {e}\")\n",
        "            return None\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch = [b for b in batch if b is not None]\n",
        "    return torch.utils.data.dataloader.default_collate(batch) if batch else (torch.empty(0), torch.empty(0))\n",
        "\n",
        "# 画像前処理（学習時）\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((PX, PX)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# 画像前処理（検証時）\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((PX, PX)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# デバイス設定\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# サンプルのカスタムモデル（ResNet50 ベース、回帰出力）\n",
        "class CustomResNet50(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomResNet50, self).__init__()\n",
        "        self.model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, 1)  # 回帰用出力1つ\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def train_one_epoch(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, targets in train_loader:\n",
        "        images, targets = images.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "def validate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    predictions, actuals = [], []\n",
        "    with torch.no_grad():\n",
        "        for images, targets in val_loader:\n",
        "            images, targets = images.to(device), targets.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, targets)\n",
        "            total_loss += loss.item()\n",
        "            predictions.extend(outputs.cpu().numpy())\n",
        "            actuals.extend(targets.cpu().numpy())\n",
        "    return total_loss / len(val_loader), np.array(predictions), np.array(actuals)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "# ✅ Bland-Altman Plot\n",
        "\n",
        "def bland_altman_plot(data1, data2):\n",
        "    mean = (data1 + data2) / 2\n",
        "    diff = data1 - data2\n",
        "    plt.scatter(mean, diff, alpha=0.5)\n",
        "    plt.axhline(np.mean(diff), color='gray', linestyle='--')\n",
        "    plt.axhline(np.mean(diff) + 1.96 * np.std(diff), color='red', linestyle='--')\n",
        "    plt.axhline(np.mean(diff) - 1.96 * np.std(diff), color='red', linestyle='--')\n",
        "    plt.xlabel(\"Mean of Predicted and Actual\")\n",
        "    plt.ylabel(\"Difference (Predicted - Actual)\")\n",
        "    plt.title('Bland-Altman Plot')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(filtered_df)):\n",
        "    print(f\"Fold {fold+1}/{NUM_FOLDS}\")\n",
        "    train_dataset = SimpleImageDataset(filtered_df.iloc[train_idx], train_transforms)\n",
        "    val_dataset = SimpleImageDataset(filtered_df.iloc[val_idx], val_transforms)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    model = CustomResNet50().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    best_loss = float(\"inf\")\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        val_loss, predictions, actuals = validate(model, val_loader, criterion, device)\n",
        "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= PATIENCE:\n",
        "                print(\"Early stopping triggered\")\n",
        "                break\n",
        "\n",
        "    errors = predictions - actuals\n",
        "    result_df = pd.DataFrame({\n",
        "        \"Fold\": fold + 1,\n",
        "        \"Predicted\": predictions.flatten(),\n",
        "        \"Actual\": actuals.flatten(),\n",
        "        \"Error\": errors.flatten()\n",
        "    })\n",
        "    result_csv_path = os.path.join(output_folder, f\"fold_{fold+1}_predictions.csv\")\n",
        "    result_df.to_csv(result_csv_path, index=False)\n",
        "    print(f\"Saved predictions to {result_csv_path}\")\n",
        "\n",
        "    bland_altman_plot(predictions, actuals)"
      ],
      "metadata": {
        "id": "qrK87CPS23h7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import ResNet50_Weights\n",
        "from torch.optim import lr_scheduler\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import KFold\n",
        "import datetime\n",
        "\n",
        "# ✅ 設定\n",
        "PX = 64  # 画像サイズ\n",
        "BATCH_SIZE = 64\n",
        "PATIENCE = 30\n",
        "EPOCHS = 300\n",
        "NUM_FOLDS = 5\n",
        "csv_path = \"/content/drive/MyDrive/Pixel_Comparison2Y3MPatient13R_Tracks_1_to_1010.csv\"\n",
        "cropped_img_dir = \"/content/drive/MyDrive/Patient13R_Cropped\"\n",
        "\n",
        "# ✅ タイムスタンプ付きフォルダ作成\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "output_folder = f\"results_{timestamp}\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# ✅ データ読み込みとフィルタリング\n",
        "first_characters = \"Pt13R_2_0M\"\n",
        "df = pd.read_csv(csv_path)\n",
        "filtered_df = df[df[\"File Prefix1\"].str.startswith(first_characters)].reset_index(drop=True)\n",
        "\n",
        "# ✅ データセットの定義\n",
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, folder_path, df, transform):\n",
        "        self.transform = transform\n",
        "        self.folder_path = folder_path\n",
        "        self.item_paths = [\n",
        "            os.path.join(self.folder_path, i).replace(\"Photo\", \"AF\").replace(\"_2_0M\", \"_4_1M\")\n",
        "            for i in df[\"File Prefix1\"]\n",
        "        ]\n",
        "        self.ratio = df[\"Ratio\"].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.item_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.item_paths[idx]\n",
        "        if not os.path.exists(image_path):\n",
        "            raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
        "        pil_image = Image.open(image_path).convert(\"RGB\")\n",
        "        tensor_image = self.transform(pil_image)\n",
        "        target = torch.tensor([self.ratio[idx]], dtype=torch.float32)\n",
        "        return tensor_image, target\n",
        "\n",
        "# ✅ 画像前処理\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(PX, scale=(0.75, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(5),\n",
        "    transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.005),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.ConvertImageDtype(torch.float32),\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((PX, PX)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.ConvertImageDtype(torch.float32),\n",
        "])\n",
        "\n",
        "# ✅ モデル定義\n",
        "class LaserSpotResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.resnet = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "        self.resnet.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.resnet.maxpool = nn.Identity()\n",
        "        self.resnet.fc = nn.Identity()\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(2048, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet(x)\n",
        "        return self.regressor(x)\n",
        "\n",
        "# ✅ Early Stopping\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "        self.best_model = None\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if self.best_loss is None or val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "            self.best_model = model.state_dict().copy()\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        return self.early_stop\n",
        "\n",
        "# ✅ 5-Fold Cross Validation\n",
        "kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "all_predictions = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(filtered_df)):\n",
        "    print(f\"\\n===== Fold {fold+1}/{NUM_FOLDS} =====\")\n",
        "\n",
        "    train_subset = filtered_df.iloc[train_idx]\n",
        "    val_subset = filtered_df.iloc[val_idx]\n",
        "\n",
        "    train_dataset = SimpleImageDataset(cropped_img_dir, train_subset, train_transforms)\n",
        "    val_dataset = SimpleImageDataset(cropped_img_dir, val_subset, val_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    model = LaserSpotResNet().to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.001)\n",
        "    scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, total_steps=EPOCHS * len(train_loader))\n",
        "    early_stopping = EarlyStopping(patience=PATIENCE, min_delta=1e-4)\n",
        "\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        scheduler.step()\n",
        "\n",
        "        if early_stopping(running_loss, model):\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "    model.load_state_dict(early_stopping.best_model)\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            predictions.extend(outputs.cpu().numpy().flatten())\n",
        "\n",
        "    val_subset = val_subset.copy()\n",
        "    val_subset[\"Prediction\"] = predictions\n",
        "    val_subset.to_csv(f\"{output_folder}/predictions_fold_{fold+1}.csv\", index=False)\n",
        "    all_predictions.append(val_subset)\n",
        "\n",
        "print(\"\\n✅ 5-Fold Cross Validation Complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "rlBF6ZtE24Ph",
        "outputId": "51b7e2da-6dca-481b-e00f-38f68db2b70a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Fold 1/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 202MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping triggered\n",
            "\n",
            "===== Fold 2/5 =====\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-84311e7da0f9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#修正後\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import ResNet50_Weights\n",
        "from torch.optim import lr_scheduler\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import KFold\n",
        "import datetime\n",
        "\n",
        "# ✅ 設定\n",
        "PX = 64\n",
        "BATCH_SIZE = 64\n",
        "PATIENCE = 30\n",
        "EPOCHS = 300\n",
        "NUM_FOLDS = 5\n",
        "csv_path = \"/content/drive/MyDrive/Pixel_Comparison2Y3MPatient13R_Tracks_1_to_1010.csv\"\n",
        "cropped_img_dir = \"/content/drive/MyDrive/Patient13R_Cropped\"\n",
        "\n",
        "# ✅ タイムスタンプ付きフォルダ作成\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "output_folder = f\"results_{timestamp}\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# ✅ データ読み込みとフィルタリング\n",
        "first_characters = \"Pt13R_2_0M\"\n",
        "df = pd.read_csv(csv_path)\n",
        "filtered_df = df[df[\"File Prefix1\"].str.startswith(first_characters)].reset_index(drop=True)\n",
        "\n",
        "# ✅ データセットの定義\n",
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, folder_path, df, transform):\n",
        "        self.transform = transform\n",
        "        self.folder_path = folder_path\n",
        "        self.item_paths = [\n",
        "            os.path.join(self.folder_path, i).replace(\"Photo\", \"AF\").replace(\"_2_0M\", \"_4_1M\")\n",
        "            for i in df[\"File Prefix1\"]\n",
        "        ]\n",
        "        self.ratio = df[\"Ratio\"].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.item_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.item_paths[idx]\n",
        "        if not os.path.exists(image_path):\n",
        "            raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
        "        pil_image = Image.open(image_path).convert(\"RGB\")\n",
        "        tensor_image = self.transform(pil_image)\n",
        "        target = torch.tensor([self.ratio[idx]], dtype=torch.float32)\n",
        "        return tensor_image, target\n",
        "\n",
        "# ✅ 画像前処理\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(PX, scale=(0.75, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(5),\n",
        "    transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.005),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.ConvertImageDtype(torch.float32),\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((PX, PX)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.ConvertImageDtype(torch.float32),\n",
        "])\n",
        "\n",
        "# ✅ モデル定義\n",
        "class LaserSpotResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.resnet = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "        self.resnet.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.resnet.maxpool = nn.Identity()\n",
        "        self.resnet.fc = nn.Identity()\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(2048, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet(x)\n",
        "        return self.regressor(x)\n",
        "\n",
        "# ✅ Early Stopping\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "        self.best_model = None\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if self.best_loss is None or val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "            self.best_model = model.state_dict().copy()\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        return self.early_stop\n",
        "\n",
        "# ✅ 5-Fold Cross Validation\n",
        "kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "all_predictions = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(filtered_df)):\n",
        "    print(f\"\\n===== Fold {fold+1}/{NUM_FOLDS} =====\")\n",
        "\n",
        "    train_subset = filtered_df.iloc[train_idx]\n",
        "    val_subset = filtered_df.iloc[val_idx]\n",
        "\n",
        "    train_dataset = SimpleImageDataset(cropped_img_dir, train_subset, train_transforms)\n",
        "    val_dataset = SimpleImageDataset(cropped_img_dir, val_subset, val_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    model = LaserSpotResNet().to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.001)\n",
        "    scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, total_steps=EPOCHS * len(train_loader))\n",
        "    early_stopping = EarlyStopping(patience=PATIENCE, min_delta=1e-4)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        scheduler.step()\n",
        "\n",
        "        avg_train_loss = running_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        if early_stopping(avg_train_loss, model):\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(train_losses, label=\"Train Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.savefig(f\"{output_folder}/loss_curve_fold_{fold+1}.png\")\n",
        "    plt.close()\n",
        "\n",
        "print(\"\\n✅ 5-Fold Cross Validation Complete!\")"
      ],
      "metadata": {
        "id": "FpgmxOYnJGRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f5EK1I-sJNLs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}